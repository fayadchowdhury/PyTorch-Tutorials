{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018cc3f2",
   "metadata": {},
   "source": [
    "#### Complete logistic regression pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addabdae",
   "metadata": {},
   "source": [
    "The steps in this pipeline are the same with some minor differences\n",
    "<ul>\n",
    "    <li>Define model in terms of input size and output size</li>\n",
    "    <li>Define loss function (BCEloss here) and optimiser</li>\n",
    "    <li>Training loop</li>\n",
    "    <ul>\n",
    "        <li>Predict using model</li>\n",
    "        <li>Compute loss</li>\n",
    "        <li>loss.backward()</li>\n",
    "        <li>Optimiser step</li>\n",
    "        <li>Zero out gradients</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353563c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler # To scale data to a fixed range\n",
    "from sklearn.model_selection import train_test_split # To split the data into train and test batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a31b3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "bc = datasets.load_breast_cancer() # Breast cancer dataset presenting a binary classification problem\n",
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e93e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input and output sizes\n",
    "num_samples, num_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3fd5f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # Take 20% of data as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb4643fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features to a 0 mean and unit variance\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) # Fit to the training set\n",
    "X_test = sc.transform(X_test) # Transform testing set accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5483d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to pytorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a830f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to column vector\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db5ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model class\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_features, 1) # Linear layer has only one output (0 or 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c11df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 1e-2\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53b84a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = LogisticRegression(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddce1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73dba313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.521\n",
      "Epoch: 20, loss: 0.448\n",
      "Epoch: 30, loss: 0.399\n",
      "Epoch: 40, loss: 0.363\n",
      "Epoch: 50, loss: 0.335\n",
      "Epoch: 60, loss: 0.313\n",
      "Epoch: 70, loss: 0.295\n",
      "Epoch: 80, loss: 0.279\n",
      "Epoch: 90, loss: 0.266\n",
      "Epoch: 100, loss: 0.255\n",
      "Epoch: 110, loss: 0.245\n",
      "Epoch: 120, loss: 0.236\n",
      "Epoch: 130, loss: 0.228\n",
      "Epoch: 140, loss: 0.221\n",
      "Epoch: 150, loss: 0.215\n",
      "Epoch: 160, loss: 0.209\n",
      "Epoch: 170, loss: 0.204\n",
      "Epoch: 180, loss: 0.199\n",
      "Epoch: 190, loss: 0.194\n",
      "Epoch: 200, loss: 0.190\n",
      "Epoch: 210, loss: 0.186\n",
      "Epoch: 220, loss: 0.182\n",
      "Epoch: 230, loss: 0.179\n",
      "Epoch: 240, loss: 0.176\n",
      "Epoch: 250, loss: 0.173\n",
      "Epoch: 260, loss: 0.170\n",
      "Epoch: 270, loss: 0.167\n",
      "Epoch: 280, loss: 0.165\n",
      "Epoch: 290, loss: 0.162\n",
      "Epoch: 300, loss: 0.160\n",
      "Epoch: 310, loss: 0.158\n",
      "Epoch: 320, loss: 0.156\n",
      "Epoch: 330, loss: 0.154\n",
      "Epoch: 340, loss: 0.152\n",
      "Epoch: 350, loss: 0.150\n",
      "Epoch: 360, loss: 0.148\n",
      "Epoch: 370, loss: 0.146\n",
      "Epoch: 380, loss: 0.145\n",
      "Epoch: 390, loss: 0.143\n",
      "Epoch: 400, loss: 0.142\n",
      "Epoch: 410, loss: 0.140\n",
      "Epoch: 420, loss: 0.139\n",
      "Epoch: 430, loss: 0.138\n",
      "Epoch: 440, loss: 0.137\n",
      "Epoch: 450, loss: 0.135\n",
      "Epoch: 460, loss: 0.134\n",
      "Epoch: 470, loss: 0.133\n",
      "Epoch: 480, loss: 0.132\n",
      "Epoch: 490, loss: 0.131\n",
      "Epoch: 500, loss: 0.130\n",
      "Epoch: 510, loss: 0.129\n",
      "Epoch: 520, loss: 0.128\n",
      "Epoch: 530, loss: 0.127\n",
      "Epoch: 540, loss: 0.126\n",
      "Epoch: 550, loss: 0.125\n",
      "Epoch: 560, loss: 0.124\n",
      "Epoch: 570, loss: 0.124\n",
      "Epoch: 580, loss: 0.123\n",
      "Epoch: 590, loss: 0.122\n",
      "Epoch: 600, loss: 0.121\n",
      "Epoch: 610, loss: 0.120\n",
      "Epoch: 620, loss: 0.120\n",
      "Epoch: 630, loss: 0.119\n",
      "Epoch: 640, loss: 0.118\n",
      "Epoch: 650, loss: 0.118\n",
      "Epoch: 660, loss: 0.117\n",
      "Epoch: 670, loss: 0.116\n",
      "Epoch: 680, loss: 0.116\n",
      "Epoch: 690, loss: 0.115\n",
      "Epoch: 700, loss: 0.115\n",
      "Epoch: 710, loss: 0.114\n",
      "Epoch: 720, loss: 0.114\n",
      "Epoch: 730, loss: 0.113\n",
      "Epoch: 740, loss: 0.112\n",
      "Epoch: 750, loss: 0.112\n",
      "Epoch: 760, loss: 0.111\n",
      "Epoch: 770, loss: 0.111\n",
      "Epoch: 780, loss: 0.110\n",
      "Epoch: 790, loss: 0.110\n",
      "Epoch: 800, loss: 0.109\n",
      "Epoch: 810, loss: 0.109\n",
      "Epoch: 820, loss: 0.109\n",
      "Epoch: 830, loss: 0.108\n",
      "Epoch: 840, loss: 0.108\n",
      "Epoch: 850, loss: 0.107\n",
      "Epoch: 860, loss: 0.107\n",
      "Epoch: 870, loss: 0.106\n",
      "Epoch: 880, loss: 0.106\n",
      "Epoch: 890, loss: 0.106\n",
      "Epoch: 900, loss: 0.105\n",
      "Epoch: 910, loss: 0.105\n",
      "Epoch: 920, loss: 0.104\n",
      "Epoch: 930, loss: 0.104\n",
      "Epoch: 940, loss: 0.104\n",
      "Epoch: 950, loss: 0.103\n",
      "Epoch: 960, loss: 0.103\n",
      "Epoch: 970, loss: 0.103\n",
      "Epoch: 980, loss: 0.102\n",
      "Epoch: 990, loss: 0.102\n",
      "Epoch: 1000, loss: 0.102\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    predicted_output = model(X_train)\n",
    "    # Loss\n",
    "    loss = criterion(predicted_output, y_train)\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    # Zero out gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch+1}, loss: {loss.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fed02bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "with torch.no_grad():\n",
    "    test_prediction = model(X_test)\n",
    "    test_prediction = test_prediction.round() # Binary classification ( >= 0.5 -> 1, 0 otherwise)\n",
    "    acc = test_prediction.eq(y_test).sum() / float(y_test.shape[0]) # Accuracy calculated as number of correctly classified samples\n",
    "    print(f\"Accuracy: {acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e8aaa7",
   "metadata": {},
   "source": [
    "Here a few things were done differently:\n",
    "<ul>\n",
    "    <li>Binary classification problem required the use of logistic regression</li>\n",
    "    <li>Forward pass of logistic regresison requires calculating sigmoid of dense layers' output</li>\n",
    "    <li>Evaluation was done on test set</li>\n",
    "    <li>StandardScaler was used to transofrm inputs to 0 mean and unit standard deviation</li>\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
